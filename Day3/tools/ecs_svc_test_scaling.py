import boto3
import json
import re
import time
from datetime import datetime, timedelta
from statistics import mean
import concurrent.futures

class DualMetricAutoscaler:
    def __init__(self, cluster_name, asg_name=None):
        self.ecs = boto3.client('ecs', region_name='ap-northeast-2')
        self.logs = boto3.client('logs', region_name='ap-northeast-2')
        self.cloudwatch = boto3.client('cloudwatch', region_name='ap-northeast-2')
        self.autoscaling = boto3.client('autoscaling', region_name='ap-northeast-2')
        self.cluster_name = cluster_name
        self.asg_name = asg_name or f"{cluster_name}-asg"
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (ìºì‹œ ì—†ìŒ)
        self.log_query_timeout = 5   # 5ì´ˆ ë¹ ë¥¸ íƒ€ì„ì•„ì›ƒ
        self.log_sample_size = 100   # ì ì€ ìƒ˜í”Œë¡œ ë¹ ë¥¸ ì²˜ë¦¬
        
        # ì„œë¹„ìŠ¤ë³„ ì„¤ì • (ë©”ëª¨ë¦¬ ì œê±°, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)
        self.services = {
            'product-svc': {
                'log_group': '/ecs/logs/product',
                'response_time_threshold': 0.3,
                'cpu_threshold': 95,  # ë” ë‚®ì€ ì„ê³„ê°’
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 2  # ë” ë¹ ë¥¸ ë°˜ì‘
            },
            'stress-svc': {
                'log_group': '/ecs/logs/stress',
                'response_time_threshold': 0.5,
                'cpu_threshold': 80,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 2
            },
            'user-svc': {
                'log_group': '/ecs/logs/user',
                'response_time_threshold': 0.3,
                'cpu_threshold': 95,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 2
            }
        }
        
        self.scale_up_cooldown = 30   # ë” ì§§ì€ ì¿¨ë‹¤ìš´
        self.scale_down_cooldown = 180
        
        # Auto Scaling Group ì„¤ì •
        self.asg_config = {
            'min_size': 1,
            'desired_capacity': 1,
            'max_size': 10
        }
        
        # ASG ì´ˆê¸° ì„¤ì •
        self.setup_asg()
    
    def setup_asg(self):
        """ì´ˆê¸° ASG ì„¤ì •"""
        try:
            self.autoscaling.update_auto_scaling_group(
                AutoScalingGroupName=self.asg_name,
                MinSize=self.asg_config['min_size'],
                DesiredCapacity=self.asg_config['desired_capacity'],
                MaxSize=self.asg_config['max_size']
            )
            print(f"âš™ï¸ ASG ì„¤ì • ì™„ë£Œ: ìµœì†Œ {self.asg_config['min_size']}ê°œ, ì›í•˜ëŠ” {self.asg_config['desired_capacity']}ê°œ, ìµœëŒ€ {self.asg_config['max_size']}ê°œ", flush=True)
        except Exception as e:
            print(f"âš ï¸ ASG ì„¤ì • ì‹¤íŒ¨: {e}", flush=True)
    
    def get_current_instance_count(self):
        """í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°íšŒ"""
        try:
            response = self.autoscaling.describe_auto_scaling_groups(
                AutoScalingGroupNames=[self.asg_name]
            )
            if response['AutoScalingGroups']:
                asg = response['AutoScalingGroups'][0]
                return {
                    'desired': asg['DesiredCapacity'],
                    'running': len([i for i in asg['Instances'] if i['LifecycleState'] == 'InService']),
                    'total': len(asg['Instances'])
                }
        except Exception as e:
            print(f"âš ï¸ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}", flush=True)
        return {'desired': 0, 'running': 0, 'total': 0}
    
    def get_current_task_count(self, service_name):
        try:
            response = self.ecs.describe_services(
                cluster=self.cluster_name,
                services=[service_name]
            )
            return response['services'][0]['desiredCount']
        except:
            return 0
    
    def get_cpu_utilization(self, service_name):
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=5)
        
        # EC2 ì¸ìŠ¤í„´ìŠ¤ CPU ì§ì ‘ ì¡°íšŒ
        instance_ids = self.get_asg_instance_ids()
        if instance_ids:
            all_cpu_values = []
            for instance_id in instance_ids:
                try:
                    response = self.cloudwatch.get_metric_statistics(
                        Namespace='AWS/EC2',
                        MetricName='CPUUtilization',
                        Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
                        StartTime=start_time,
                        EndTime=end_time,
                        Period=300,
                        Statistics=['Average', 'Maximum']
                    )
                    
                    if response['Datapoints']:
                        latest = max(response['Datapoints'], key=lambda x: x['Timestamp'])
                        cpu_value = latest.get('Maximum', latest.get('Average', 0))
                        all_cpu_values.append(cpu_value)
                except Exception:
                    pass
            
            if all_cpu_values:
                return sum(all_cpu_values) / len(all_cpu_values)
        
        # ECS ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ ì‹œë„
        try:
            response = self.cloudwatch.get_metric_statistics(
                Namespace='AWS/ECS',
                MetricName='CPUUtilization',
                Dimensions=[
                    {'Name': 'ServiceName', 'Value': service_name},
                    {'Name': 'ClusterName', 'Value': self.cluster_name}
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=300,
                Statistics=['Average', 'Maximum']
            )
            
            if response['Datapoints']:
                latest = max(response['Datapoints'], key=lambda x: x['Timestamp'])
                return latest.get('Maximum', latest.get('Average', 0))
        except Exception:
            pass
        
        return 75.0  # íŠ¸ë˜í”½ ìˆìŒ ì¶”ì •ê°’
    
    def get_asg_instance_ids(self):
        try:
            response = self.autoscaling.describe_auto_scaling_groups(
                AutoScalingGroupNames=[self.asg_name]
            )
            if response['AutoScalingGroups']:
                asg = response['AutoScalingGroups'][0]
                return [i['InstanceId'] for i in asg['Instances'] if i['LifecycleState'] == 'InService']
        except Exception:
            pass
        return []
    
    def get_average_response_time(self, log_group_name):
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=2)
        
        query = """
        fields @timestamp, @message
        | sort @timestamp desc
        | limit 100
        """
        
        try:
            response = self.logs.start_query(
                logGroupName=log_group_name,
                startTime=int(start_time.timestamp()),
                endTime=int(end_time.timestamp()),
                queryString=query
            )
            
            # ë¹ ë¥¸ ì¿¼ë¦¬ ëŒ€ê¸°
            max_wait = 25
            wait_count = 0
            while wait_count < max_wait:
                result = self.logs.get_query_results(queryId=response['queryId'])
                if result['status'] == 'Complete':
                    break
                elif result['status'] == 'Failed':
                    return 0.5
                time.sleep(0.2)
                wait_count += 1
            
            if result['status'] != 'Complete':
                return 0.5
            
            if len(result['results']) == 0:
                return 0.4
            
            response_times = []
            patterns = [
                (r'\|\s*(\d+(?:\.\d+)?)ms\s*\|', 1000),
                (r'\|\s*(\d+(?:\.\d+)?)Âµs\s*\|', 1000000),
                (r'(\d+(?:\.\d+)?)ms', 1000),
                (r'(\d+(?:\.\d+)?)Âµs', 1000000),
            ]
            
            for log_entry in result['results']:
                try:
                    message = ""
                    for field in log_entry:
                        if field['field'] == '@message':
                            message = field['value']
                            break
                    
                    if not message:
                        continue
                    
                    for pattern, divisor in patterns:
                        matches = re.findall(pattern, message)
                        for match in matches:
                            try:
                                time_value = float(match)
                                time_seconds = time_value / divisor
                                if 0.0001 <= time_seconds <= 60:
                                    response_times.append(time_seconds)
                                    break
                            except ValueError:
                                continue
                        if response_times and len(response_times) >= 10:
                            break
                except Exception:
                    continue
            
            if response_times:
                return mean(response_times)
            else:
                return 0.6
                
        except Exception:
            return 0.5
            

    
    def scale_service(self, service_name, desired_count, reason):
        current_time = time.time()
        service_config = self.services[service_name]
        
        desired_count = max(service_config['min_tasks'], 
                          min(service_config['max_tasks'], desired_count))
        
        try:
            self.ecs.update_service(
                cluster=self.cluster_name,
                service=service_name,
                desiredCount=desired_count
            )
            
            service_config['last_scale_time'] = current_time
            print(f"âœ… {service_name}: {desired_count}ê°œ íƒœìŠ¤í¬ë¡œ ìŠ¤ì¼€ì¼ë§ ({reason})", flush=True)
            return True
            
        except Exception as e:
            print(f"âŒ {service_name} ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}", flush=True)
            return False
    
    def get_metrics_parallel(self, service_name, service_config):
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            cpu_future = executor.submit(self.get_cpu_utilization, service_name)
            response_future = executor.submit(self.get_average_response_time, service_config['log_group'])
            
            cpu_utilization = cpu_future.result(timeout=10)
            avg_response_time = response_future.result(timeout=10)
            
        return cpu_utilization, avg_response_time
    
    def auto_scale_service(self, service_name):
        service_config = self.services[service_name]
        
        current_tasks = self.get_current_task_count(service_name)
        
        # ë³‘ë ¬ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        try:
            cpu_utilization, avg_response_time = self.get_metrics_parallel(service_name, service_config)
        except concurrent.futures.TimeoutError:
            print(f"  â° {service_name} ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒ€ì„ì•„ì›ƒ", flush=True)
            return
        
        # ê¸°ë³¸ ìƒíƒœ ë¡œê¹… (í•œ ì¤„ë¡œ)
        print(f"{service_name}: {current_tasks}ê°œ íƒœìŠ¤í¬, ì‘ë‹µì‹œê°„: {avg_response_time:.6f}ì´ˆ, CPU: {cpu_utilization:.1f}%", flush=True)
        
        # ìŠ¤ì¼€ì¼ë§ ê²°ì • ë¡œì§
        should_scale_up = False
        scale_reason = ""
        
        response_exceeded = avg_response_time > service_config['response_time_threshold']
        cpu_exceeded = cpu_utilization > service_config['cpu_threshold']
        
        if response_exceeded and cpu_exceeded:
            should_scale_up = True
            scale_reason = f"ì‘ë‹µì‹œê°„ {avg_response_time:.3f}s > {service_config['response_time_threshold']}s & CPU {cpu_utilization:.1f}% > {service_config['cpu_threshold']}%"
        
        # ìŠ¤ì¼€ì¼ ì—… (ì—°ì† ì¡°ê±´ ë§Œì¡± ì²´í¬)
        if should_scale_up:
            service_config['violation_count'] += 1
            print(f"  ğŸ¯ {service_name} ìŠ¤ì¼€ì¼ë§ ì¡°ê±´ ë§Œì¡± ({service_config['violation_count']}/{service_config['violation_threshold']}): {scale_reason}", flush=True)
            
            # ì—°ì† ìœ„ë°˜ ì²´í¬
            if service_config['violation_count'] >= service_config['violation_threshold']:
                # ì¿¨ë‹¤ìš´ ì²´í¬
                current_time = time.time()
                cooldown_remaining = self.scale_up_cooldown - (current_time - service_config['last_scale_time'])
                if cooldown_remaining > 0:
                    print(f"  â³ {service_name} ìŠ¤ì¼€ì¼ë§ ì¿¨ë‹¤ìš´ ì¤‘ ({int(cooldown_remaining)}ì´ˆ ë‚¨ìŒ)", flush=True)
                    return
                
                new_count = min(current_tasks + 1, service_config['max_tasks'])
                
                if new_count > current_tasks:
                    print(f"  ğŸ”¥ 1ê°œ ì¦ê°€: {scale_reason}", flush=True)
                    self.scale_service(service_name, new_count, scale_reason)
                    service_config['violation_count'] = 0  # ìŠ¤ì¼€ì¼ë§ í›„ ë¦¬ì…‹
                else:
                    print(f"  âš ï¸ ì´ë¯¸ ìµœëŒ€ íƒœìŠ¤í¬ ìˆ˜ ë„ë‹¬: {current_tasks}ê°œ", flush=True)
        else:
            # ì¡°ê±´ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ ìœ„ë°˜ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            service_config['violation_count'] = 0
            
            # ìŠ¤ì¼€ì¼ ë‹¤ìš´ (ì™„í™”ëœ ì¡°ê±´)
            if (avg_response_time < 0.2 and 
                cpu_utilization < 30 and 
                current_tasks > service_config['min_tasks']):
                
                current_time = time.time()
                if current_time - service_config['last_scale_time'] > 180:  # 3ë¶„ ì¿¨ë‹¤ìš´
                    new_count = max(service_config['min_tasks'], current_tasks - 1)
                    reason = f"ë¦¬ì†ŒìŠ¤ ì—¬ìœ  (ì‘ë‹µì‹œê°„: {avg_response_time:.3f}s, CPU: {cpu_utilization:.1f}%)"
                    print(f"  â¬‡ï¸ {reason}", flush=True)
                    self.scale_service(service_name, new_count, reason)
    
    def run(self):
        print("ì´ì¤‘ ë©”íŠ¸ë¦­ ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ ì‹œì‘ (AND ì¡°ê±´: ì‘ë‹µì‹œê°„ & CPU ëª¨ë‘ ì´ˆê³¼ì‹œ ìŠ¤ì¼€ì¼ë§ - ì—°ì† 2ë²ˆ ìœ„ë°˜ì‹œ ìŠ¤ì¼€ì¼ë§)", flush=True)
        print(f"ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤: {list(self.services.keys())}", flush=True)
        
        while True:
            try:
                print(f"\n=== {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===", flush=True)
                
                # ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ í‘œì‹œ
                instance_info = self.get_current_instance_count()
                print(f"ğŸ’» ì¸ìŠ¤í„´ìŠ¤: {instance_info['running']}/{instance_info['desired']}ê°œ", flush=True)
                
                for service_name in self.services.keys():
                    self.auto_scale_service(service_name)
                
                time.sleep(1)   # 1ì´ˆë§ˆë‹¤ ì²´í¬
                
            except KeyboardInterrupt:
                print("\nì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ ì¢…ë£Œ", flush=True)
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)
                time.sleep(60)

def main():
    autoscaler = DualMetricAutoscaler(
        cluster_name="apdev-ecs-cluster",
        asg_name="apdev-ecs-asg"
    )
    autoscaler.run()

if __name__ == "__main__":
    main()
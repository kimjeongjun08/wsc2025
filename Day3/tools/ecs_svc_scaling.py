import boto3
import json
import re
import time
import os
import sys
from datetime import datetime, timedelta
from statistics import mean
import concurrent.futures

# Windows UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

class DualMetricAutoscaler:
    def __init__(self, cluster_name, asg_name=None):
        self.ecs = boto3.client('ecs', region_name='ap-northeast-2')
        self.logs = boto3.client('logs', region_name='ap-northeast-2')
        self.cloudwatch = boto3.client('cloudwatch', region_name='ap-northeast-2')
        self.autoscaling = boto3.client('autoscaling', region_name='ap-northeast-2')
        self.cluster_name = cluster_name
        self.asg_name = asg_name or f"{cluster_name}-asg"
        
        # ìºì‹œ ì œê±° - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
        
        # ë¡œê·¸ ì¿¼ë¦¬ ìµœì í™” (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)
        self.log_query_timeout = 15  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
        self.log_sample_size = 200   # ìƒ˜í”Œ í¬ê¸° ì¦ê°€
        
        # ì„œë¹„ìŠ¤ë³„ ì„¤ì • (ì—°ì† ì¡°ê±´ ë§Œì¡± ì²´í¬)
        self.services = {
            'product-svc': {
                'log_group': '/ecs/logs/product',
                'response_time_threshold': 0.3,
                'cpu_threshold': 95,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,  # ì—°ì† ìœ„ë°˜ íšŸìˆ˜
                'violation_threshold': 5  # 5ë²ˆ ì—°ì† ìœ„ë°˜ì‹œ ìŠ¤ì¼€ì¼ë§
            },
            'stress-svc': {
                'log_group': '/ecs/logs/stress',
                'response_time_threshold': 0.5,
                'cpu_threshold': 110,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 5
            },
            'user-svc': {
                'log_group': '/ecs/logs/user',
                'response_time_threshold': 0.3,
                'cpu_threshold': 95,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 5
            }
        }
        
        self.scale_up_cooldown = 60   # 1ë¶„ ì¿¨ë‹¤ìš´
        self.scale_down_cooldown = 300  # 5ë¶„ìœ¼ë¡œ ì¦ê°€
        
        # Auto Scaling Group ì„¤ì •
        self.asg_config = {
            'min_size': 1,
            'desired_capacity': 1,
            'max_size': 10
        }
        
        # ASG ì´ˆê¸° ì„¤ì •
        self.setup_asg()
    
    def setup_asg(self):
        """ì´ˆê¸° ASG ì„¤ì •"""
        try:
            self.autoscaling.update_auto_scaling_group(
                AutoScalingGroupName=self.asg_name,
                MinSize=self.asg_config['min_size'],
                DesiredCapacity=self.asg_config['desired_capacity'],
                MaxSize=self.asg_config['max_size']
            )
            print(f"âš™ï¸ ASG ì„¤ì • ì™„ë£Œ: ìµœì†Œ {self.asg_config['min_size']}ê°œ, ì›í•˜ëŠ” {self.asg_config['desired_capacity']}ê°œ, ìµœëŒ€ {self.asg_config['max_size']}ê°œ", flush=True)
        except Exception as e:
            print(f"âš ï¸ ASG ì„¤ì • ì‹¤íŒ¨ (ASG ë¯¸ìƒì„± ìƒíƒœì¼ ìˆ˜ ìˆìŒ): {e}", flush=True)
    
    def get_current_instance_count(self):
        """í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°íšŒ"""
        try:
            response = self.autoscaling.describe_auto_scaling_groups(
                AutoScalingGroupNames=[self.asg_name]
            )
            if response['AutoScalingGroups']:
                asg = response['AutoScalingGroups'][0]
                return {
                    'desired': asg['DesiredCapacity'],
                    'running': len([i for i in asg['Instances'] if i['LifecycleState'] == 'InService']),
                    'total': len(asg['Instances'])
                }
        except Exception as e:
            print(f"âš ï¸ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}", flush=True)
        return {'desired': 0, 'running': 0, 'total': 0}
    
    def get_current_task_count(self, service_name):
        try:
            response = self.ecs.describe_services(
                cluster=self.cluster_name,
                services=[service_name]
            )
            return response['services'][0]['desiredCount']
        except:
            return 0
    
    def get_cpu_utilization(self, service_name, minutes=60):  # 1ì‹œê°„ìœ¼ë¡œ í™•ì¥
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=minutes)
        
        print(f"  ğŸ” CPU ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹œì‘: {service_name} ({start_time.strftime('%H:%M')} ~ {end_time.strftime('%H:%M')})", flush=True)
        
        try:
            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
            attempts = [
                # ì‹œë„ 1: ì„œë¹„ìŠ¤ + í´ëŸ¬ìŠ¤í„°
                {
                    'dimensions': [{'Name': 'ServiceName', 'Value': service_name}, {'Name': 'ClusterName', 'Value': self.cluster_name}],
                    'period': 300
                },
                # ì‹œë„ 2: ì„œë¹„ìŠ¤ + í´ëŸ¬ìŠ¤í„° (1ë¶„ ê°„ê²©)
                {
                    'dimensions': [{'Name': 'ServiceName', 'Value': service_name}, {'Name': 'ClusterName', 'Value': self.cluster_name}],
                    'period': 60
                },
                # ì‹œë„ 3: í´ëŸ¬ìŠ¤í„°ë§Œ
                {
                    'dimensions': [{'Name': 'ClusterName', 'Value': self.cluster_name}],
                    'period': 300
                }
            ]
            
            for i, attempt in enumerate(attempts, 1):
                print(f"    ì‹œë„ {i}: {attempt['dimensions']}, Period: {attempt['period']}ì´ˆ", flush=True)
                
                response = self.cloudwatch.get_metric_statistics(
                    Namespace='AWS/ECS',
                    MetricName='CPUUtilization',
                    Dimensions=attempt['dimensions'],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=attempt['period'],
                    Statistics=['Average', 'Maximum']
                )
                
                print(f"    ê²°ê³¼: {len(response['Datapoints'])}ê°œ ë°ì´í„°í¬ì¸íŠ¸", flush=True)
                
                if response['Datapoints']:
                    # ë°ì´í„°í¬ì¸íŠ¸ ìƒì„¸ ì •ë³´
                    for dp in response['Datapoints']:
                        timestamp = dp['Timestamp'].strftime('%H:%M:%S')
                        avg = dp.get('Average', 0)
                        maximum = dp.get('Maximum', 0)
                        print(f"      {timestamp}: í‰ê·  {avg:.1f}%, ìµœëŒ€ {maximum:.1f}%", flush=True)
                    
                    # ìµœì‹  ë°ì´í„° ì‚¬ìš©
                    latest = max(response['Datapoints'], key=lambda x: x['Timestamp'])
                    current_cpu = latest.get('Maximum', latest.get('Average', 0))
                    
                    print(f"  âœ… CPU ë°œê²¬: {current_cpu:.1f}% (ìµœì‹  ë°ì´í„°: {latest['Timestamp'].strftime('%H:%M:%S')})", flush=True)
                    return current_cpu
            
            # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
            print(f"  âŒ ëª¨ë“  CPU ë©”íŠ¸ë¦­ ì‹œë„ ì‹¤íŒ¨ ({service_name})", flush=True)
            
            # ECS ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            try:
                ecs_response = self.ecs.describe_services(
                    cluster=self.cluster_name,
                    services=[service_name]
                )
                if ecs_response['services']:
                    service = ecs_response['services'][0]
                    print(f"    ECS ì„œë¹„ìŠ¤ ìƒíƒœ: {service['status']}, ì‹¤í–‰ ì¤‘: {service['runningCount']}ê°œ", flush=True)
                else:
                    print(f"    ECS ì„œë¹„ìŠ¤ ì°¾ì„ ìˆ˜ ì—†ìŒ: {service_name}", flush=True)
            except Exception as ecs_e:
                print(f"    ECS ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {ecs_e}", flush=True)
            
            return 0
            
        except Exception as e:
            print(f"  âŒ CPU ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨ ({service_name}): {e}", flush=True)
            return 0
    

    
    def get_average_response_time(self, log_group_name, seconds=30):  # 30ì´ˆë¡œ ë‹¨ì¶•
        end_time = datetime.now()
        start_time = end_time - timedelta(seconds=seconds)
        
        # ë” ë§ì€ ë¡œê·¸ ìƒ˜í”Œ ìˆ˜ì§‘ (ì‹¤ì‹œê°„ì„± í–¥ìƒ)
        query = f"""
        fields @timestamp, @message
        | sort @timestamp desc
        | limit 200
        """
        
        try:
            response = self.logs.start_query(
                logGroupName=log_group_name,
                startTime=int(start_time.timestamp()),
                endTime=int(end_time.timestamp()),
                queryString=query
            )
            
            # ë¡œê·¸ ì¿¼ë¦¬ ëŒ€ê¸° (15ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¦ê°€)
            max_wait = 75  # 15ì´ˆ ìµœëŒ€ ëŒ€ê¸° (0.2 * 75 = 15ì´ˆ)
            wait_count = 0
            while wait_count < max_wait:
                result = self.logs.get_query_results(queryId=response['queryId'])
                if result['status'] == 'Complete':
                    break
                time.sleep(0.2)  # 0.2ì´ˆì”© ëŒ€ê¸°
                wait_count += 1
            
            if result['status'] != 'Complete':
                print(f"  â° ë¡œê·¸ ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ (15ì´ˆ)", flush=True)
                return 0
            
            response_times = []
            # ë” í¬ê´„ì ì¸ ì •ê·œì‹ íŒ¨í„´
            patterns = [
                (r'\|\s*(\d+\.\d+)ms\s*\|', 1000),      # GIN ms
                (r'\|\s*(\d+\.\d+)Âµs\s*\|', 1000000),   # GIN Âµs  
                (r'\|\s*(\d+)ms\s*\|', 1000),           # GIN ms (ì •ìˆ˜)
                (r'\|\s*(\d+)Âµs\s*\|', 1000000),        # GIN Âµs (ì •ìˆ˜)
                (r'(\d+\.\d+)ms\b', 1000),              # ë‹¨ìˆœ ms
                (r'(\d+\.\d+)Âµs\b', 1000000),           # ë‹¨ìˆœ Âµs
                (r'(\d+)ms\b', 1000),                   # ë‹¨ìˆœ ms (ì •ìˆ˜)
                (r'(\d+)Âµs\b', 1000000),                # ë‹¨ìˆœ Âµs (ì •ìˆ˜)
                (r'latency["\s:=]*(\d+\.\d+)', 1),      # latency: 1.234
                (r'duration["\s:=]*(\d+\.\d+)', 1),     # duration: 1.234
                (r'time["\s:=]*(\d+\.\d+)', 1),         # time: 1.234
            ]
            
            print(f"  ğŸ“Š ë¡œê·¸ ì—”íŠ¸ë¦¬ ìˆ˜: {len(result['results'])}", flush=True)
            
            for log_entry in result['results']:
                try:
                    log_message = ""
                    for field in log_entry:
                        if field['field'] == '@message':
                            log_message = field['value']
                            break
                    
                    if not log_message:
                        continue
                    
                    # JSON íŒŒì‹± ì‹œë„
                    try:
                        if log_message.startswith('{'):
                            log_data = json.loads(log_message)
                            gin_log = log_data.get('log', log_message)
                        else:
                            gin_log = log_message
                    except:
                        gin_log = log_message
                    
                    # ëª¨ë“  íŒ¨í„´ ì‹œë„
                    for pattern, divisor in patterns:
                        matches = re.findall(pattern, gin_log)
                        for match in matches:
                            try:
                                time_value = float(match)
                                time_seconds = time_value / divisor
                                
                                if 0.0001 <= time_seconds <= 30:  # ë²”ìœ„ í™•ì¥
                                    response_times.append(time_seconds)
                            except:
                                continue
                            
                except Exception:
                    continue
            
            print(f"  ğŸ“ˆ ì‘ë‹µì‹œê°„ ìƒ˜í”Œ ìˆ˜: {len(response_times)}", flush=True)
            if response_times:
                print(f"  ğŸ“Š ì‘ë‹µì‹œê°„ ë²”ìœ„: {min(response_times):.4f}s ~ {max(response_times):.4f}s", flush=True)
            
            # í‰ê· ê°’ ì‚¬ìš© (ë” ì•ˆì •ì )
            result_value = mean(response_times) if response_times else 0
            return result_value
            
        except Exception as e:
            print(f"  âŒ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}", flush=True)
            return 0
    
    def scale_service(self, service_name, desired_count, reason):
        current_time = time.time()
        service_config = self.services[service_name]
        
        desired_count = max(service_config['min_tasks'], 
                          min(service_config['max_tasks'], desired_count))
        
        try:
            self.ecs.update_service(
                cluster=self.cluster_name,
                service=service_name,
                desiredCount=desired_count
            )
            
            service_config['last_scale_time'] = current_time
            print(f"âœ… {service_name}: {desired_count}ê°œ íƒœìŠ¤í¬ë¡œ ìŠ¤ì¼€ì¼ë§ ({reason})", flush=True)
            return True
            
        except Exception as e:
            print(f"âŒ {service_name} ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}", flush=True)
            return False
    
    def get_metrics_parallel(self, service_name, service_config):
        """ë³‘ë ¬ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ì œê±°)"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            cpu_future = executor.submit(self.get_cpu_utilization, service_name)
            response_future = executor.submit(self.get_average_response_time, service_config['log_group'])
            
            cpu_utilization = cpu_future.result(timeout=10)  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            avg_response_time = response_future.result(timeout=20)  # 20ì´ˆ íƒ€ì„ì•„ì›ƒ
            
        return cpu_utilization, avg_response_time
    
    def auto_scale_service(self, service_name):
        service_config = self.services[service_name]
        
        current_tasks = self.get_current_task_count(service_name)
        
        # ë³‘ë ¬ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ì œê±°)
        try:
            cpu_utilization, avg_response_time = self.get_metrics_parallel(service_name, service_config)
        except concurrent.futures.TimeoutError:
            print(f"  â° {service_name} ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒ€ì„ì•„ì›ƒ", flush=True)
            return
        
        # ê¸°ë³¸ ìƒíƒœ ë¡œê¹… (ë©”ëª¨ë¦¬ ì œê±°)
        print(f"{service_name}: {current_tasks}ê°œ íƒœìŠ¤í¬, ì‘ë‹µì‹œê°„: {avg_response_time:.6f}ì´ˆ, CPU: {cpu_utilization:.1f}%", flush=True)
        
        # ìŠ¤ì¼€ì¼ë§ ê²°ì • ë¡œì§ (30ì´ˆ ì´ë‚´ ìŠ¤ì¼€ì¼ë§ ëª©í‘œ)
        should_scale_up = False
        scale_reason = ""
        
        # ìŠ¤ì¼€ì¼ë§ ì¡°ê±´: ì‘ë‹µì‹œê°„ & CPU ëª¨ë‘ ì´ˆê³¼
        response_exceeded = avg_response_time > service_config['response_time_threshold']
        cpu_exceeded = cpu_utilization > service_config['cpu_threshold']
        
        # ì‘ë‹µì‹œê°„&CPU ëª¨ë‘ ì´ˆê³¼ì‹œ ìŠ¤ì¼€ì¼ë§
        if response_exceeded and cpu_exceeded:
            should_scale_up = True
            scale_reason = f"ì‘ë‹µì‹œê°„ {avg_response_time:.3f}s > {service_config['response_time_threshold']}s & CPU {cpu_utilization:.1f}% > {service_config['cpu_threshold']}%"
        
        # ìŠ¤ì¼€ì¼ ì—… (ì—°ì† ì¡°ê±´ ë§Œì¡± ì²´í¬)
        if should_scale_up:
            service_config['violation_count'] += 1
            print(f"  ğŸ¯ {service_name} ìŠ¤ì¼€ì¼ë§ ì¡°ê±´ ë§Œì¡± ({service_config['violation_count']}/{service_config['violation_threshold']}): {scale_reason}", flush=True)
            
            # ì—°ì† ìœ„ë°˜ ì²´í¬
            if service_config['violation_count'] >= service_config['violation_threshold']:
                # ì¿¨ë‹¤ìš´ ì²´í¬ (ì¤‘ë³µ ìŠ¤ì¼€ì¼ë§ ë°©ì§€)
                current_time = time.time()
                cooldown_remaining = self.scale_up_cooldown - (current_time - service_config['last_scale_time'])
                if cooldown_remaining > 0:
                    print(f"  â³ {service_name} ìŠ¤ì¼€ì¼ë§ ì¿¨ë‹¤ìš´ ì¤‘ ({int(cooldown_remaining)}ì´ˆ ë‚¨ìŒ)", flush=True)
                    return
                
                # ìµœì†Œí•œ ì¦ê°€ (í•­ìƒ 1ê°œì”©ë§Œ)
                increment = 1  # í•­ìƒ 1ê°œì”©ë§Œ ì¦ê°€
                
                new_count = min(current_tasks + increment, service_config['max_tasks'])
                
                print(f"  ğŸ“Š ìŠ¤ì¼€ì¼ë§ ê³„ì‚°: {current_tasks} + {increment} = {new_count} (ìµœëŒ€: {service_config['max_tasks']})", flush=True)
                
                if new_count > current_tasks:
                    print(f"  ğŸ”¥ {increment}ê°œ ì¦ê°€: {scale_reason}", flush=True)
                    self.scale_service(service_name, new_count, scale_reason)
                    service_config['violation_count'] = 0  # ìŠ¤ì¼€ì¼ë§ í›„ ë¦¬ì…‹
                else:
                    print(f"  âš ï¸ ì´ë¯¸ ìµœëŒ€ íƒœìŠ¤í¬ ìˆ˜ ë„ë‹¬: {current_tasks}ê°œ (ìµœëŒ€: {service_config['max_tasks']})", flush=True)
        else:
            # ì¡°ê±´ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ ìœ„ë°˜ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            service_config['violation_count'] = 0
            
            # ìŠ¤ì¼€ì¼ ë‹¤ìš´ (ì™„í™”ëœ ì¡°ê±´ - ë©”ëª¨ë¦¬ ì œê±°)
            if (avg_response_time < 0.2 and 
                cpu_utilization < 30 and 
                current_tasks > service_config['min_tasks']):
                
                current_time = time.time()
                if current_time - service_config['last_scale_time'] > 180:  # 3ë¶„ ì¿¨ë‹¤ìš´
                    new_count = max(service_config['min_tasks'], current_tasks - 1)
                    reason = f"ë¦¬ì†ŒìŠ¤ ì—¬ìœ  (ì‘ë‹µì‹œê°„: {avg_response_time:.3f}s, CPU: {cpu_utilization:.1f}%)"
                    print(f"  â¬‡ï¸ {reason}", flush=True)
                    self.scale_service(service_name, new_count, reason)
            
            # ê°•ì œ ìŠ¤ì¼€ì¼ ë‹¤ìš´ (ìµœëŒ€ê°’ ì´ˆê³¼ ì‹œ)
            if current_tasks > service_config['max_tasks']:
                new_count = service_config['max_tasks']
                reason = f"ìµœëŒ€ íƒœìŠ¤í¬ ìˆ˜ ì´ˆê³¼ ({current_tasks} > {service_config['max_tasks']})"
                print(f"  â¬‡ï¸ ê°•ì œ ìŠ¤ì¼€ì¼ ë‹¤ìš´: {reason}", flush=True)
                self.scale_service(service_name, new_count, reason)
    
    def run(self):
        print("ì´ì¤‘ ë©”íŠ¸ë¦­ ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ ì‹œì‘ (AND ì¡°ê±´: ì‘ë‹µì‹œê°„ 0.3ì´ˆ & CPU 95% - ì—°ì† 5ë²ˆ ìœ„ë°˜ì‹œ ìŠ¤ì¼€ì¼ë§)", flush=True)
        print(f"ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤: {list(self.services.keys())}", flush=True)
        
        while True:
            try:
                print(f"\n=== {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===", flush=True)
                
                # ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ í‘œì‹œ
                instance_info = self.get_current_instance_count()
                print(f"ğŸ’» ì¸ìŠ¤í„´ìŠ¤: {instance_info['running']}/{instance_info['desired']}ê°œ (ìµœëŒ€: {self.asg_config['max_size']}ê°œ)", flush=True)
                
                for service_name in self.services.keys():
                    self.auto_scale_service(service_name)
                
                time.sleep(1)   # 1ì´ˆë§ˆë‹¤ ì²´í¬ (ë¹ ë¥¸ ê°ì§€)
                
            except KeyboardInterrupt:
                print("\nì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ ì¢…ë£Œ", flush=True)
                break
            except Exception as e:
                import traceback
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)
                print(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}", flush=True)
                print("60ì´ˆ í›„ ì¬ì‹œë„...", flush=True)
                time.sleep(60)

def main():
    autoscaler = DualMetricAutoscaler(
        cluster_name="apdev-ecs-cluster",  # ì‹¤ì œ í´ëŸ¬ìŠ¤í„° ì´ë¦„ìœ¼ë¡œ ë³€ê²½
        asg_name="apdev-ecs-asg"   # ì‹¤ì œ ASG ì´ë¦„ìœ¼ë¡œ ë³€ê²½
    )
    autoscaler.run()

if __name__ == "__main__":
    main()
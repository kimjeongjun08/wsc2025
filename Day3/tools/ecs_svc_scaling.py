import boto3
import json
import re
import time
from datetime import datetime, timedelta, timezone
from statistics import mean, stdev
import concurrent.futures
from collections import deque

class SmartTrafficAutoscaler:
    def __init__(self, cluster_name, asg_name=None):
        self.ecs = boto3.client('ecs', region_name='ap-northeast-2')
        self.logs = boto3.client('logs', region_name='ap-northeast-2')
        self.cloudwatch = boto3.client('cloudwatch', region_name='ap-northeast-2')
        self.autoscaling = boto3.client('autoscaling', region_name='ap-northeast-2')
        self.cluster_name = cluster_name
        self.asg_name = asg_name or f"{cluster_name}-asg"
        
        # íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.traffic_history = {
            'product-svc': {'cpu': deque(maxlen=20), 'response': deque(maxlen=20), 'timestamps': deque(maxlen=20)},
            'stress-svc': {'cpu': deque(maxlen=20), 'response': deque(maxlen=20), 'timestamps': deque(maxlen=20)},
            'user-svc': {'cpu': deque(maxlen=20), 'response': deque(maxlen=20), 'timestamps': deque(maxlen=20)}
        }
        
        # ì„œë¹„ìŠ¤ë³„ ì„¤ì •
        self.services = {
            'product-svc': {
                'log_group': '/ecs/logs/product',
                'response_time_threshold': 0.3,
                'cpu_threshold_gradual': 40,
                'cpu_threshold_spike': 90,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 3,
                'current_pattern': 'unknown',
                'pattern_confidence': 0
            },
            'stress-svc': {
                'log_group': '/ecs/logs/stress',
                'response_time_threshold': 0.3,
                'cpu_threshold_gradual': 110,
                'cpu_threshold_spike': 110,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 3,
                'current_pattern': 'unknown',
                'pattern_confidence': 0
            },
            'user-svc': {
                'log_group': '/ecs/logs/user',
                'response_time_threshold': 0.3,
                'cpu_threshold_gradual': 40,
                'cpu_threshold_spike': 90,
                'min_tasks': 1,
                'max_tasks': 6,
                'last_scale_time': 0,
                'violation_count': 0,
                'violation_threshold': 3,
                'current_pattern': 'unknown',
                'pattern_confidence': 0
            }
        }
        
        self.scale_up_cooldown = 90  # 1ë¶„ 30ì´ˆ
        self.scale_down_cooldown = 300
        
        # Auto Scaling Group ì„¤ì •
        self.asg_config = {
            'min_size': 1,
            'desired_capacity': 1,
            'max_size': 10
        }
        
        self.setup_asg()
    
    def setup_asg(self):
        """ì´ˆê¸° ASG ì„¤ì •"""
        try:
            self.autoscaling.update_auto_scaling_group(
                AutoScalingGroupName=self.asg_name,
                MinSize=self.asg_config['min_size'],
                DesiredCapacity=self.asg_config['desired_capacity'],
                MaxSize=self.asg_config['max_size']
            )
            print(f"ASG ì„¤ì • ì™„ë£Œ: {self.asg_config['min_size']}-{self.asg_config['max_size']}ê°œ")
        except Exception as e:
            print(f"ASG ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def analyze_traffic_pattern(self, service_name, cpu_utilization, response_time):
        """íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„"""
        history = self.traffic_history[service_name]
        current_time = time.time()
        
        history['cpu'].append(cpu_utilization)
        history['response'].append(response_time)
        history['timestamps'].append(current_time)
        
        if len(history['cpu']) < 10:
            return 'unknown', 0, 40
        
        recent_cpu = list(history['cpu'])[-10:]
        recent_times = list(history['timestamps'])[-10:]
        
        try:
            # ë³€í™”ìœ¨ ê³„ì‚°
            cpu_changes = []
            for i in range(1, len(recent_cpu)):
                if recent_times[i] - recent_times[i-1] > 0:
                    rate = (recent_cpu[i] - recent_cpu[i-1]) / (recent_times[i] - recent_times[i-1])
                    cpu_changes.append(abs(rate))
            
            if not cpu_changes:
                return 'unknown', 0, 40
            
            avg_change_rate = mean(cpu_changes)
            max_change_rate = max(cpu_changes)
            
            # ë³€ë™ì„± ê³„ì‚°
            cpu_std = stdev(recent_cpu) if len(recent_cpu) > 1 else 0
            cpu_mean = mean(recent_cpu)
            coefficient_of_variation = (cpu_std / cpu_mean) if cpu_mean > 0 else 0
            
            # íŒ¨í„´ ê²°ì •
            service_config = self.services[service_name]
            
            if max_change_rate > 10 or coefficient_of_variation > 0.5:
                pattern = 'spike'
                cpu_threshold = service_config['cpu_threshold_spike']
                confidence = min(80, max_change_rate * 5)
            elif avg_change_rate > 1 or coefficient_of_variation > 0.3:
                pattern = 'gradual'
                cpu_threshold = service_config['cpu_threshold_gradual']
                confidence = 60
            else:
                pattern = 'gradual'  # ê¸°ë³¸ê°’
                cpu_threshold = service_config['cpu_threshold_gradual']
                confidence = 40
            
            return pattern, confidence, cpu_threshold
            
        except Exception:
            return 'unknown', 0, self.services[service_name]['cpu_threshold_gradual']
    
    def get_current_task_count(self, service_name):
        try:
            response = self.ecs.describe_services(
                cluster=self.cluster_name,
                services=[service_name]
            )
            if response['services']:
                return response['services'][0]['desiredCount']
            return 0
        except Exception:
            return 0
    
    def get_cpu_utilization(self, service_name, minutes=3):
        """CPU ì‚¬ìš©ë¥  ì¡°íšŒ"""
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(minutes=minutes)
        
        try:
            response = self.cloudwatch.get_metric_statistics(
                Namespace='AWS/ECS',
                MetricName='CPUUtilization',
                Dimensions=[
                    {'Name': 'ServiceName', 'Value': service_name},
                    {'Name': 'ClusterName', 'Value': self.cluster_name}
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=60,
                Statistics=['Average'],
                Unit='Percent'
            )
            
            if response['Datapoints']:
                datapoints = sorted(response['Datapoints'], key=lambda x: x['Timestamp'], reverse=True)
                latest = datapoints[0]
                return latest.get('Average', 0)
            return 0
            
        except Exception:
            return 0
    
    def get_memory_utilization(self, service_name, minutes=3):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°íšŒ"""
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(minutes=minutes)
        
        try:
            response = self.cloudwatch.get_metric_statistics(
                Namespace='AWS/ECS',
                MetricName='MemoryUtilization',
                Dimensions=[
                    {'Name': 'ServiceName', 'Value': service_name},
                    {'Name': 'ClusterName', 'Value': self.cluster_name}
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=60,
                Statistics=['Average', 'Maximum'],
                Unit='Percent'
            )
            
            if response['Datapoints']:
                datapoints = sorted(response['Datapoints'], key=lambda x: x['Timestamp'], reverse=True)
                latest = datapoints[0]
                return latest.get('Maximum', latest.get('Average', 0))
            return 0
            
        except Exception:
            return 0
    
    def get_average_response_time(self, log_group_name, minutes=2):
        """ì‘ë‹µì‹œê°„ ì¡°íšŒ - ê°„ì†Œí™”"""
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(minutes=minutes)
        
        # ë¡œê·¸ ê·¸ë£¹ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0 ë°˜í™˜
        try:
            # ë¡œê·¸ ê·¸ë£¹ ì¡´ì¬ í™•ì¸
            self.logs.describe_log_groups(logGroupNamePrefix=log_group_name, limit=1)
        except Exception:
            return 0
        
        query = """
        fields @timestamp, @message
        | filter @message like /ms|response|duration/
        | sort @timestamp desc
        | limit 50
        """
        
        try:
            # ë¡œê·¸ ë³´ì¡´ ê¸°ê°„ í™•ì¸ì„ ìœ„í•´ ë” ë„“ì€ ë²”ìœ„ë¡œ ì‹œì‘
            extended_start = end_time - timedelta(hours=1)  # 1ì‹œê°„ ì „ë¶€í„°
            
            response = self.logs.start_query(
                logGroupName=log_group_name,
                startTime=int(extended_start.timestamp()),
                endTime=int(end_time.timestamp()),
                queryString=query
            )
            
            # ì§§ì€ íƒ€ì„ì•„ì›ƒ
            max_wait = 25  # 5ì´ˆ
            wait_count = 0
            
            while wait_count < max_wait:
                result = self.logs.get_query_results(queryId=response['queryId'])
                
                if result['status'] == 'Complete':
                    break
                elif result['status'] == 'Failed':
                    return 0
                    
                time.sleep(0.2)
                wait_count += 1
            
            if result['status'] != 'Complete':
                return 0
            
            response_times = []
            
            # ê°„ë‹¨í•œ ì •ê·œì‹ íŒ¨í„´ë§Œ ì‚¬ìš©
            patterns = [
                (r'(\d+(?:\.\d+)?)ms\b', 1000),
                (r'"response_time"\s*:\s*(\d+(?:\.\d+)?)', 1000),
                (r'"latency"\s*:\s*(\d+(?:\.\d+)?)', 1000),
            ]
            
            for log_entry in result['results']:
                try:
                    log_message = ""
                    for field in log_entry:
                        if field['field'] == '@message':
                            log_message = field['value']
                            break
                    
                    if not log_message:
                        continue
                    
                    # JSON íŒŒì‹± ì‹œë„
                    try:
                        if log_message.strip().startswith('{'):
                            log_data = json.loads(log_message)
                            for key in ['latency', 'response_time', 'duration']:
                                if key in log_data:
                                    time_value = float(log_data[key])
                                    if 0.001 <= time_value <= 10:
                                        response_times.append(time_value)
                                        break
                    except:
                        pass
                    
                    # ì •ê·œì‹ ë§¤ì¹­
                    for pattern, divisor in patterns:
                        match = re.search(pattern, log_message, re.IGNORECASE)
                        if match:
                            try:
                                time_value = float(match.group(1))
                                time_seconds = time_value / divisor
                                
                                if 0.001 <= time_seconds <= 10:
                                    response_times.append(time_seconds)
                                    break
                            except ValueError:
                                continue
                            
                except Exception:
                    continue
            
            if response_times:
                sorted_times = sorted(response_times)
                p95_index = int(len(sorted_times) * 0.95)
                return sorted_times[p95_index] if p95_index < len(sorted_times) else sorted_times[-1]
            
            return 0
            
        except Exception:
            return 0
    
    def scale_service(self, service_name, desired_count, reason):
        current_time = time.time()
        service_config = self.services[service_name]
        
        desired_count = max(service_config['min_tasks'], 
                          min(service_config['max_tasks'], desired_count))
        
        try:
            self.ecs.update_service(
                cluster=self.cluster_name,
                service=service_name,
                desiredCount=desired_count
            )
            
            service_config['last_scale_time'] = current_time
            print(f"  â†’ ìŠ¤ì¼€ì¼ë§: {service_name} = {desired_count}ê°œ íƒœìŠ¤í¬ ({reason})")
            return True
            
        except Exception as e:
            print(f"  â†’ ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {service_name} - {e}")
            return False
    
    def auto_scale_service(self, service_name):
        service_config = self.services[service_name]
        
        current_tasks = self.get_current_task_count(service_name)
        if current_tasks == 0:
            print(f"  {service_name}: ì„œë¹„ìŠ¤ ì—†ìŒ")
            return
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        cpu_utilization = self.get_cpu_utilization(service_name)
        memory_utilization = self.get_memory_utilization(service_name)
        avg_response_time = self.get_average_response_time(service_config['log_group'])
        
        # íŒ¨í„´ ë¶„ì„
        pattern, confidence, cpu_threshold = self.analyze_traffic_pattern(
            service_name, cpu_utilization, avg_response_time
        )
        
        service_config['current_pattern'] = pattern
        service_config['pattern_confidence'] = confidence
        
        # ê°„ë‹¨í•œ ìƒíƒœ ì¶œë ¥
        print(f"  {service_name}: íƒœìŠ¤í¬={current_tasks}, ì‘ë‹µì‹œê°„={avg_response_time:.3f}ì´ˆ, CPU={cpu_utilization:.1f}%, ë©”ëª¨ë¦¬={memory_utilization:.1f}%")
        
        # ìŠ¤ì¼€ì¼ë§ ê²°ì • (OR ì¡°ê±´)
        response_exceeded = avg_response_time > service_config['response_time_threshold']
        cpu_exceeded = cpu_utilization > cpu_threshold
        
        if response_exceeded or cpu_exceeded:
            service_config['violation_count'] += 1
            
            if service_config['violation_count'] >= service_config['violation_threshold']:
                current_time = time.time()
                cooldown = self.scale_up_cooldown
                cooldown_remaining = cooldown - (current_time - service_config['last_scale_time'])
                
                if cooldown_remaining <= 0:
                    increment = 2 if pattern == 'spike' and cpu_utilization > 80 else 1
                    new_count = min(current_tasks + increment, service_config['max_tasks'])
                    
                    if new_count > current_tasks:
                        self.scale_service(service_name, new_count, f"high load ({pattern})")
                        service_config['violation_count'] = 0
        else:
            service_config['violation_count'] = 0
            
            # ìŠ¤ì¼€ì¼ ë‹¤ìš´
            if (avg_response_time < 0.15 and 
                cpu_utilization < 20 and 
                current_tasks > service_config['min_tasks']):
                
                current_time = time.time()
                if current_time - service_config['last_scale_time'] > self.scale_down_cooldown:
                    new_count = max(service_config['min_tasks'], current_tasks - 1)
                    self.scale_service(service_name, new_count, "low load")
    
    def run(self):
        print("ğŸš€ ECS Auto Scaler ì‹œì‘")
        print(f"ğŸ“‹ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤: {list(self.services.keys())}")
        
        iteration = 0
        while True:
            try:
                iteration += 1
                print(f"\n--- ë°˜ë³µ #{iteration} ({datetime.now().strftime('%H:%M:%S')}) ---")
                
                for service_name in self.services.keys():
                    try:
                        self.auto_scale_service(service_name)
                    except Exception as e:
                        print(f"  {service_name}: ì˜¤ë¥˜ - {e}")
                
                print("15ì´ˆ ëŒ€ê¸°...")
                time.sleep(15)
                
            except KeyboardInterrupt:
                print("\nì¢…ë£Œ")
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜: {e}")
                time.sleep(60)

def main():
    autoscaler = SmartTrafficAutoscaler(
        cluster_name="apdev-ecs-cluster",
        asg_name="apdev-ecs-asg"
    )
    autoscaler.run()

if __name__ == "__main__":
    main()